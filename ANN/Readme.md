Extending the concept of [Logistic Regression](https://github.com/hamzafar/deep_learning_toys/tree/master/Regression), the dense netowrk is created with combining each of logistic unit containing 
both linear and non linear operations. We have named this single unit as Neuron. 

For simplicity purpose, the two layer neural network is first made i.e. the model contanin only two hidden layers and one output layer. 
Then simple neural network is generalized to **n** number of layers and user can define varry number of hidden layer. 
The detailed work of both concepts can be found, at **Kaggle Kernel**, respectively:

1. [Two Layers Neural Network](https://www.kaggle.com/hamzafar/two-layers-neural-network)
2. [Multi-Layer Neural Network](https://www.kaggle.com/hamzafar/multi-layer-neural-network)


